{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @name regulation\n",
    "# @description notebook to build regulatory networks from various regulatory edges datasets\n",
    "# @author NÃºria Queralt Rosinach\n",
    "# @date 29-03-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do:\n",
    "#     * some edges have some resource without symbol. we need all symbols to retrieve concept\n",
    "# attributes from biothings (eg, tftarget::tred, NCBIGene:9503 (retired entrez and replaced\n",
    "# by another entrez, so it has symbol)). This is fixed here including 'retired' in the scopes cell 11\n",
    "# for nodes file. It must be fixed in tftargets notebook. This only can be fixed for 'retired'\n",
    "# Gene IDs, not for withdrawn Gene IDs.\n",
    "#     * add ref_uri: trrust, msigdb\n",
    "#     * add namespace to entrez geneLists in tred, encode, neph, msigdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from biothings_client import get_client\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./tftargets/out'): os.makedirs('./tftargets/out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_list(dictionary, key, value):\n",
    "    genes = dictionary.get(key,set())\n",
    "    for gene in value:\n",
    "        genes.add(gene)\n",
    "    dictionary[key] = genes\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TF-gene edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tred = json.load(open('tftargets/data/tred.json'))\n",
    "encode = json.load(open('tftargets/data/encode.json'))\n",
    "neph2012 = json.load(open('tftargets/data/neph2012.json'))\n",
    "trrust = json.load(open('tftargets/data/trrust.json'))\n",
    "msigdb = json.load(open('msigdb/out/tf_genelist_entrez_msigdb.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neph2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neph_all = dict()\n",
    "for cell in neph2012:\n",
    "    for tf, genes in neph2012[cell].items():\n",
    "        neph_all = unique_list(neph_all, tf, genes)\n",
    "neph = {key: list(neph_all[key]) for key in neph_all}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize 2 entrez, HGNC Id\n",
    "\n",
    "* **symbols**: TF, trrust.genes \n",
    "* **entrez**: tred.genes, encode.genes, neph.genes, msigdb.genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input ID list: symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbols \n",
    "trrust_genes = { gene for tf in trrust for gene in trrust.get(tf) }\n",
    "symbols = list(tred.keys() | encode.keys() | neph.keys() | trrust.keys() | msigdb.keys() | trrust_genes)\n",
    "print('symbols:', len(symbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ID dictionaries: symbol2entrez, symbol2hgnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query biothings for symbol2entrez and symbol2hgnc \n",
    "mg = get_client('gene')\n",
    "df = mg.querymany(symbols, scopes = 'symbol,alias', fields='entrezgene,HGNC', size=1, as_dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not found\n",
    "missing = df[['notfound']].copy()\n",
    "missing = missing.reset_index().rename(columns={'query': 'symbol'})\n",
    "missing = missing[missing['notfound'] == True][['symbol']] \n",
    "missing_symbol_l = [ symbol for symbol in missing['symbol'] ]\n",
    "\n",
    "# save not found\n",
    "with open('./tftargets/out/not_found_symbols.list','w') as f:\n",
    "    f.write('\\n'.join(missing_symbol_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare ids dataframe for dictionary construction\n",
    "ids =( df.reset_index()\n",
    "         .rename(columns={'query': 'symbol','HGNC': 'hgnc'}) \n",
    "         [['symbol','hgnc','entrezgene']]\n",
    "         .copy()\n",
    "     )\n",
    "ids['entrez'] = ids.entrezgene.apply(lambda x: str(round(x)) if x > 0 else 0)\n",
    "print('symbol:', type(ids['symbol'][0]))\n",
    "print('hgnc:', type(ids['hgnc'][0]))\n",
    "print('entrez:', type(ids['entrez'][0]))\n",
    "ids.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of not found value\n",
    "ids[ids['symbol'] == 'ALPHACP1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of found value\n",
    "ids[ids['symbol'] == 'NPC1L1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionaries\n",
    "# value types: \n",
    "# symbol=> str, no nulls\n",
    "# hgnc=> str, null=> float(nan)\n",
    "# entrez=> str, null=> float(0)\n",
    "# dictionaries for ID mapping (nulls allowed). No namespace added.\n",
    "#symbol2entrez_map = dict(zip(ids.symbol,ids.entrez))\n",
    "#symbol2hgnc_map = dict(zip(ids.symbol,ids.hgnc))\n",
    "\n",
    "# dictionaries for normalization to an ID (not null allowed). the final ID must be from one of the several schemes.\n",
    "# namespace added.\n",
    "symbol2entrez_dict = dict(zip(ids.symbol,ids.entrez))\n",
    "symbol2hgnc_dict = dict(zip(ids.symbol,ids.hgnc))\n",
    "\n",
    "# associate symbol for those genes without entrez: symbol => entrez > symbol\n",
    "for symbol in symbol2entrez_dict:\n",
    "    if symbol2entrez_dict[symbol] == 0:\n",
    "        symbol2entrez_dict[symbol] = symbol\n",
    "    else: \n",
    "        entrez = symbol2entrez_dict[symbol]\n",
    "        symbol2entrez_dict[symbol] = \"NCBIGene:\"+entrez\n",
    "\n",
    "# associate entrez else symbol for those genes without hgnc: symbol =>  hgnc > entrez > symbol\n",
    "for symbol in symbol2hgnc_dict:\n",
    "    if isinstance(symbol2hgnc_dict.get(symbol),float):\n",
    "        symbol2hgnc_dict[symbol] = symbol2entrez_dict[symbol]\n",
    "    else:\n",
    "        hgnc = symbol2hgnc_dict[symbol]\n",
    "        symbol2hgnc_dict[symbol] = \"HGNC:\"+hgnc\n",
    "        \n",
    "# checks\n",
    "# nor hgnc neither entrez associated\n",
    "print(symbol2entrez_dict['ALPHACP1'])\n",
    "print(symbol2hgnc_dict['ALPHACP1'])\n",
    "\n",
    "# hgnc and entrez associated\n",
    "print(symbol2entrez_dict['NPC1L1'])\n",
    "print(symbol2hgnc_dict['NPC1L1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize ID to entrez, else: symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map symbols to entrez\n",
    "tred_entrez = { symbol2entrez_dict[symbol]: tred[symbol] for symbol in tred }\n",
    "encode_entrez = { symbol2entrez_dict[symbol]: encode[symbol] for symbol in encode }\n",
    "neph_entrez = { symbol2entrez_dict[symbol]: neph[symbol] for symbol in neph }\n",
    "msigdb_entrez = { symbol2entrez_dict[symbol]: msigdb[symbol] for symbol in msigdb }\n",
    "trrust_entrez = {}\n",
    "for symbol in trrust: \n",
    "    genes_entrez = list()\n",
    "    for gene in trrust.get(symbol):\n",
    "        genes_entrez.append(symbol2entrez_dict[gene])\n",
    "    trrust_entrez[symbol2entrez_dict[symbol]] =  genes_entrez\n",
    "    \n",
    "# save associations normalized to entrez\n",
    "with open('./tftargets/out/tred_entrez.json', 'w') as f:\n",
    "    json.dump(tred_entrez, f, sort_keys=True, indent=2)\n",
    "\n",
    "with open('./tftargets/out/encode_entrez.json', 'w') as f:\n",
    "    json.dump(encode_entrez, f, sort_keys=True, indent=2)\n",
    "    \n",
    "with open('./tftargets/out/neph_entrez.json', 'w') as f:\n",
    "    json.dump(neph_entrez, f, sort_keys=True, indent=2)\n",
    "    \n",
    "with open('./tftargets/out/msigdb_entrez.json', 'w') as f:\n",
    "    json.dump(msigdb_entrez, f, sort_keys=True, indent=2)\n",
    "    \n",
    "with open('./tftargets/out/trrust_entrez.json', 'w') as f:\n",
    "    json.dump(trrust_entrez, f, sort_keys=True, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018-03-30\n",
    "**Check**:\n",
    "* neph and neph_entrez len are not equivalent, why? same with msigdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check map symbols to entrez\n",
    "len(neph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neph_entrez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msigdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msigdb_entrez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the missing keys?\n",
    "# check that 50 symbols without entrez,hgnc are in the dictionaries: \n",
    "print(neph.keys() & neph_entrez.keys())\n",
    "print(msigdb.keys() & msigdb_entrez.keys())\n",
    "print(len(msigdb.keys() & msigdb_entrez.keys()))\n",
    "# yes, 49 + 'CRX' which is in both datasets\n",
    "\n",
    "# the missing values can be 2 symbols that share the same entrez because they are alias for the same gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018-04-02\n",
    "#### Input ID list: entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrez\n",
    "tred_genes = { gene for tf in tred for gene in tred.get(tf) }\n",
    "encode_genes = { gene for tf in encode for gene in encode.get(tf) }\n",
    "neph_genes = { gene for tf in neph for gene in neph.get(tf) }\n",
    "msigdb_genes = { gene for tf in msigdb for gene in msigdb.get(tf) }\n",
    "entrez = list(tred_genes | encode_genes | neph_genes | msigdb_genes)\n",
    "print('entrez:', len(entrez))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ID dictionaries: entrez2hgnc, entrez2symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol2entrez dict\n",
    "mg = get_client('gene')\n",
    "df = mg.querymany(entrez, scopes = 'entrezgene', fields='HGNC,symbol', size=1, as_dataframe=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not found\n",
    "missing = df[['notfound']].copy()\n",
    "missing = missing.reset_index().rename(columns={'query': 'entrez'})\n",
    "missing = missing[missing['notfound'] == True][['entrez']] \n",
    "missing_entrez_l = [ entrez for entrez in missing['entrez'] ]\n",
    "\n",
    "# save not found\n",
    "with open('./tftargets/out/not_found_entrez.list','w') as f:\n",
    "    f.write('\\n'.join(missing_entrez_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare ids dataframe for dictionary construction\n",
    "ids =( df.reset_index()\n",
    "         .rename(columns={'query': 'entrez','HGNC': 'hgnc'}) \n",
    "         [['entrez','hgnc','symbol']]\n",
    "         .copy()\n",
    "     )\n",
    "print('symbol:', type(ids['symbol'][0]))\n",
    "print('hgnc:', type(ids['hgnc'][0]))\n",
    "print('entrez:', type(ids['entrez'][0]))\n",
    "ids['entrez_id'] = ids.entrez.apply(lambda x: \"NCBIGene:\"+x if type(x) == str else x)\n",
    "ids['hgnc_id'] = ids.hgnc.apply(lambda x: \"HGNC:\"+x if type(x) == str else x)\n",
    "ids.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionaries\n",
    "# value types:\n",
    "# entrez=> str, no nulls\n",
    "# symbol=> str, null=> float(nan)\n",
    "# hgnc=> str, null=> float(nan)\n",
    "# dictionaries for normalization to an ID (not null allowed). the final ID must be from one of the several schemes.\n",
    "# namespace added.\n",
    "entrez2hgnc_dict = dict(zip(ids.entrez_id,ids.hgnc_id))\n",
    "entrez2symbol_dict = dict(zip(ids.entrez_id,ids.symbol))\n",
    "\n",
    "# associate entrez for those genes without hgnc: entrez=> hgnc > entrez\n",
    "for entrez in entrez2hgnc_dict:\n",
    "    if isinstance(entrez2hgnc_dict.get(entrez),float): \n",
    "        entrez2hgnc_dict[entrez] = entrez\n",
    "        \n",
    "# associate symbol, else 'NA' because it's a dict to annotate: entrez=> symbol or 'NA'\n",
    "for entrez in entrez2symbol_dict:\n",
    "    if isinstance(entrez2symbol_dict.get(entrez),float): \n",
    "        entrez2symbol_dict[entrez] = 'NA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize ID to hgnc, else: entrez/symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Map symbols,entrez to hgnc\n",
    "tred_hgnc = { symbol2hgnc_dict[symbol]: tred[symbol] for symbol in tred }\n",
    "encode_hgnc = { symbol2hgnc_dict[symbol]: encode[symbol] for symbol in encode }\n",
    "neph_hgnc = { symbol2hgnc_dict[symbol]: neph[symbol] for symbol in neph }\n",
    "msigdb_hgnc = { symbol2hgnc_dict[symbol]: msigdb[symbol] for symbol in msigdb }\n",
    "\n",
    "trrust_hgnc = {}\n",
    "for symbol in trrust: \n",
    "    genes_hgnc = list()\n",
    "    for gene in trrust.get(symbol):\n",
    "        genes_hgnc.append(symbol2hgnc_dict[gene])\n",
    "    trrust_hgnc[symbol2hgnc_dict[symbol]] =  genes_hgnc\n",
    "\n",
    "for tf in tred_hgnc: \n",
    "    genes_hgnc = list()\n",
    "    for gene in tred_hgnc.get(tf):\n",
    "        genes_hgnc.append(entrez2hgnc_dict[\"NCBIGene:\"+str(gene)])\n",
    "    tred_hgnc[tf] =  genes_hgnc\n",
    "for tf in encode_hgnc: \n",
    "    genes_hgnc = list()\n",
    "    for gene in encode_hgnc.get(tf):\n",
    "        genes_hgnc.append(entrez2hgnc_dict[\"NCBIGene:\"+str(gene)])\n",
    "    encode_hgnc[tf] =  genes_hgnc\n",
    "for tf in neph_hgnc: \n",
    "    genes_hgnc = list()\n",
    "    for gene in neph_hgnc.get(tf):\n",
    "        genes_hgnc.append(entrez2hgnc_dict[\"NCBIGene:\"+str(gene)])\n",
    "    neph_hgnc[tf] =  genes_hgnc\n",
    "for tf in msigdb_hgnc: \n",
    "    genes_hgnc = list()\n",
    "    for gene in msigdb_hgnc.get(tf):\n",
    "        genes_hgnc.append(entrez2hgnc_dict[\"NCBIGene:\"+str(gene)])\n",
    "    msigdb_hgnc[tf] =  genes_hgnc\n",
    "    \n",
    "# save associations normalized to hgnc\n",
    "with open('./tftargets/out/tred_hgnc.json', 'w') as f:\n",
    "    json.dump(tred_hgnc, f, sort_keys=True, indent=2)\n",
    "\n",
    "with open('./tftargets/out/encode_hgnc.json', 'w') as f:\n",
    "    json.dump(encode_hgnc, f, sort_keys=True, indent=2)\n",
    "    \n",
    "with open('./tftargets/out/neph_hgnc.json', 'w') as f:\n",
    "    json.dump(neph_hgnc, f, sort_keys=True, indent=2)\n",
    "    \n",
    "with open('./tftargets/out/msigdb_hgnc.json', 'w') as f:\n",
    "    json.dump(msigdb_hgnc, f, sort_keys=True, indent=2)\n",
    "    \n",
    "with open('./tftargets/out/trrust_hgnc.json', 'w') as f:\n",
    "    json.dump(trrust_hgnc, f, sort_keys=True, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save edges\n",
    "\n",
    "Edge format:\n",
    "\n",
    "| source | dataset | tf_source_id | gene_source_id | source_uri | s_entrez_id | s_hgnc_id | s_symbol | p_id | p_label | o_entrez_id | o_hgnc_id | o_symbol | reference_id | reference_date | \n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "\n",
    "1. `source`: str tftargets\n",
    "2. `dataset`: str tred \n",
    "3. `tf_source_id`: str transcriptor factor tftargets id\n",
    "4. `gene_source_id`: str gene tftargets id \n",
    "5. `source_uri`: str 'https://github.com/slowkow/tftargets' \n",
    "6. `s_entrez_id`: str subject entrez \n",
    "7. `s_hgnc_id`: str subject hgnc id \n",
    "8. `s_symbol`: str subject label \n",
    "9. `p_id`:  str property id 'RO:0002434'\n",
    "10. `p_label`: str property label 'interacts with'\n",
    "11. `o_entrez_id`: str object entrez \n",
    "12. `o_hgnc_id`: str object hgnc id \n",
    "13. `o_symbol`: str object label  \n",
    "14. `reference_id`: str pmid \n",
    "15. `reference_date`: str yyyy-mm-dd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tftargets: tred, encode, neph, trrust\n",
    "with open('./tftargets/out/tftargets_edges.csv','w') as f:\n",
    "    f.write(\"source,dataset,tf_source_id,gene_source_id,source_uri,s_entrez_id,s_hgnc_id,s_symbol,p_id,p_label,o_entrez_id,o_hgnc_id,o_symbol,reference_id,reference_date\\n\")\n",
    "    source = \"tftargets\"\n",
    "    source_uri = \"https://github.com/slowkow/tftargets\"\n",
    "    p_id = \"RO:0002434\"\n",
    "    p_label = \"interacts with\"\n",
    "    # tred\n",
    "    dataset = \"tred\"\n",
    "    reference_id = \"PMID:17202159\"\n",
    "    reference_date = \"2007-01-01\"\n",
    "    for tf in tred:\n",
    "        for gene in tred[tf]:\n",
    "            f.write(\n",
    "                \"{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\"\n",
    "                .format(\n",
    "                    source,\n",
    "                    dataset,\n",
    "                    tf,\n",
    "                    gene,\n",
    "                    source_uri,\n",
    "                    symbol2entrez_dict[tf],\n",
    "                    symbol2hgnc_dict[tf],\n",
    "                    tf,\n",
    "                    p_id,\n",
    "                    p_label,\n",
    "                    \"NCBIGene:\"+str(gene),\n",
    "                    entrez2hgnc_dict[\"NCBIGene:\"+str(gene)],\n",
    "                    entrez2symbol_dict[\"NCBIGene:\"+str(gene)],\n",
    "                    reference_id,\n",
    "                    reference_date\n",
    "            )\n",
    "        )\n",
    "    # encode\n",
    "    dataset = \"encode_ENCFF001UUQ\"\n",
    "    reference_id = \"ENCODE:ENCFF001UUQ\"\n",
    "    reference_date = \"2012-08-28\"\n",
    "    for tf in encode:\n",
    "        for gene in encode[tf]:\n",
    "            f.write(\n",
    "                \"{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\"\n",
    "                .format(\n",
    "                    source,\n",
    "                    dataset,\n",
    "                    tf,\n",
    "                    gene,\n",
    "                    source_uri,\n",
    "                    symbol2entrez_dict[tf],\n",
    "                    symbol2hgnc_dict[tf],\n",
    "                    tf,\n",
    "                    p_id,\n",
    "                    p_label,\n",
    "                    \"NCBIGene:\"+str(gene),\n",
    "                    entrez2hgnc_dict[\"NCBIGene:\"+str(gene)],\n",
    "                    entrez2symbol_dict[\"NCBIGene:\"+str(gene)],\n",
    "                    reference_id,\n",
    "                    reference_date\n",
    "            )\n",
    "        )\n",
    "    # neph\n",
    "    dataset = \"neph2012\"\n",
    "    reference_id = \"PMID:22959076\"\n",
    "    reference_date = \"2012-09-14\"\n",
    "    for tf in neph:\n",
    "        for gene in neph[tf]:\n",
    "            f.write(\n",
    "                \"{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\"\n",
    "                .format(\n",
    "                    source,\n",
    "                    dataset,\n",
    "                    tf,\n",
    "                    gene,\n",
    "                    source_uri,\n",
    "                    symbol2entrez_dict[tf],\n",
    "                    symbol2hgnc_dict[tf],\n",
    "                    tf,\n",
    "                    p_id,\n",
    "                    p_label,\n",
    "                    \"NCBIGene:\"+str(gene),\n",
    "                    entrez2hgnc_dict[\"NCBIGene:\"+str(gene)],\n",
    "                    entrez2symbol_dict[\"NCBIGene:\"+str(gene)],\n",
    "                    reference_id,\n",
    "                    reference_date\n",
    "            )\n",
    "        )\n",
    "    # trrust\n",
    "    dataset = \"trrust\"\n",
    "    reference_id = \"PMID:26066708\"\n",
    "    reference_date = \"2015-06-12\"\n",
    "    for tf in trrust:\n",
    "        for gene in trrust[tf]:\n",
    "            f.write(\n",
    "                \"{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\"\n",
    "                .format(\n",
    "                    source,\n",
    "                    dataset,\n",
    "                    tf,\n",
    "                    gene,\n",
    "                    source_uri,\n",
    "                    symbol2entrez_dict[tf],\n",
    "                    symbol2hgnc_dict[tf],\n",
    "                    tf,\n",
    "                    p_id,\n",
    "                    p_label,\n",
    "                    symbol2entrez_dict[gene],\n",
    "                    symbol2hgnc_dict[gene],\n",
    "                    gene,\n",
    "                    reference_id,\n",
    "                    reference_date\n",
    "            )\n",
    "        )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msigdb\n",
    "if not os.path.exists('./msigdb/out'): os.makedirs('./msigdb/out')\n",
    "with open('./msigdb/out/msigdb_edges.csv','w') as f:\n",
    "    f.write(\"source,dataset,tf_source_id,gene_source_id,source_uri,s_entrez_id,s_hgnc_id,s_symbol,p_id,p_label,o_entrez_id,o_hgnc_id,o_symbol,reference_id,reference_date\\n\")\n",
    "    source = \"msigdb\"\n",
    "    source_uri = \"http://software.broadinstitute.org/gsea/msigdb\"\n",
    "    p_id = \"RO:0002434\"\n",
    "    p_label = \"interacts with\"\n",
    "    # c3:tft\n",
    "    dataset = \"c3:tft\"\n",
    "    reference_id = \"NA\"\n",
    "    reference_date = \"NA\"\n",
    "    for tf in msigdb:\n",
    "        for gene in msigdb[tf]:\n",
    "            f.write(\n",
    "                \"{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\"\n",
    "                .format(\n",
    "                    source,\n",
    "                    dataset,\n",
    "                    tf,\n",
    "                    gene,\n",
    "                    source_uri,\n",
    "                    symbol2entrez_dict[tf],\n",
    "                    symbol2hgnc_dict[tf],\n",
    "                    tf,\n",
    "                    p_id,\n",
    "                    p_label,\n",
    "                    \"NCBIGene:\"+str(gene),\n",
    "                    entrez2hgnc_dict[\"NCBIGene:\"+str(gene)],\n",
    "                    entrez2symbol_dict[\"NCBIGene:\"+str(gene)],\n",
    "                    reference_id,\n",
    "                    reference_date\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Regulation edges to build the graph\n",
    "* concat tftargets and msigdb\n",
    "* give graph format\n",
    "* build edges and nodes files\n",
    "* concat with graph (edges and nodes): first curated > monarch > regulation\n",
    "* drop duplicates ((edges/nodes) rows, concepts\n",
    "* save graph\n",
    "* format for neo4j\n",
    "* save neo4j files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concat tftargets and msigdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83310, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuria/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>dataset</th>\n",
       "      <th>tf_source_id</th>\n",
       "      <th>gene_source_id</th>\n",
       "      <th>source_uri</th>\n",
       "      <th>s_entrez_id</th>\n",
       "      <th>s_hgnc_id</th>\n",
       "      <th>s_symbol</th>\n",
       "      <th>p_id</th>\n",
       "      <th>p_label</th>\n",
       "      <th>o_entrez_id</th>\n",
       "      <th>o_hgnc_id</th>\n",
       "      <th>o_symbol</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>reference_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tftargets</td>\n",
       "      <td>tred</td>\n",
       "      <td>PAX1</td>\n",
       "      <td>5156</td>\n",
       "      <td>https://github.com/slowkow/tftargets</td>\n",
       "      <td>NCBIGene:5075</td>\n",
       "      <td>HGNC:8615</td>\n",
       "      <td>PAX1</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>NCBIGene:5156</td>\n",
       "      <td>HGNC:8803</td>\n",
       "      <td>PDGFRA</td>\n",
       "      <td>PMID:17202159</td>\n",
       "      <td>2007-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tftargets</td>\n",
       "      <td>tred</td>\n",
       "      <td>PAX1</td>\n",
       "      <td>7428</td>\n",
       "      <td>https://github.com/slowkow/tftargets</td>\n",
       "      <td>NCBIGene:5075</td>\n",
       "      <td>HGNC:8615</td>\n",
       "      <td>PAX1</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>NCBIGene:7428</td>\n",
       "      <td>HGNC:12687</td>\n",
       "      <td>VHL</td>\n",
       "      <td>PMID:17202159</td>\n",
       "      <td>2007-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source dataset tf_source_id gene_source_id  \\\n",
       "0  tftargets    tred         PAX1           5156   \n",
       "1  tftargets    tred         PAX1           7428   \n",
       "\n",
       "                             source_uri    s_entrez_id  s_hgnc_id s_symbol  \\\n",
       "0  https://github.com/slowkow/tftargets  NCBIGene:5075  HGNC:8615     PAX1   \n",
       "1  https://github.com/slowkow/tftargets  NCBIGene:5075  HGNC:8615     PAX1   \n",
       "\n",
       "         p_id         p_label    o_entrez_id   o_hgnc_id o_symbol  \\\n",
       "0  RO:0002434  interacts with  NCBIGene:5156   HGNC:8803   PDGFRA   \n",
       "1  RO:0002434  interacts with  NCBIGene:7428  HGNC:12687      VHL   \n",
       "\n",
       "    reference_id reference_date  \n",
       "0  PMID:17202159     2007-01-01  \n",
       "1  PMID:17202159     2007-01-01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tftargets\n",
    "tftargets = pd.read_csv('./tftargets/out/tftargets_edges.csv')\n",
    "print(tftargets.shape)\n",
    "tftargets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114157, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>dataset</th>\n",
       "      <th>tf_source_id</th>\n",
       "      <th>gene_source_id</th>\n",
       "      <th>source_uri</th>\n",
       "      <th>s_entrez_id</th>\n",
       "      <th>s_hgnc_id</th>\n",
       "      <th>s_symbol</th>\n",
       "      <th>p_id</th>\n",
       "      <th>p_label</th>\n",
       "      <th>o_entrez_id</th>\n",
       "      <th>o_hgnc_id</th>\n",
       "      <th>o_symbol</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>reference_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msigdb</td>\n",
       "      <td>c3:tft</td>\n",
       "      <td>AFP1</td>\n",
       "      <td>10911</td>\n",
       "      <td>http://software.broadinstitute.org/gsea/msigdb</td>\n",
       "      <td>NCBIGene:2847518</td>\n",
       "      <td>NCBIGene:2847518</td>\n",
       "      <td>AFP1</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>NCBIGene:10911</td>\n",
       "      <td>HGNC:12636</td>\n",
       "      <td>UTS2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>msigdb</td>\n",
       "      <td>c3:tft</td>\n",
       "      <td>AFP1</td>\n",
       "      <td>9241</td>\n",
       "      <td>http://software.broadinstitute.org/gsea/msigdb</td>\n",
       "      <td>NCBIGene:2847518</td>\n",
       "      <td>NCBIGene:2847518</td>\n",
       "      <td>AFP1</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>NCBIGene:9241</td>\n",
       "      <td>HGNC:7866</td>\n",
       "      <td>NOG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source dataset tf_source_id  gene_source_id  \\\n",
       "0  msigdb  c3:tft         AFP1           10911   \n",
       "1  msigdb  c3:tft         AFP1            9241   \n",
       "\n",
       "                                       source_uri       s_entrez_id  \\\n",
       "0  http://software.broadinstitute.org/gsea/msigdb  NCBIGene:2847518   \n",
       "1  http://software.broadinstitute.org/gsea/msigdb  NCBIGene:2847518   \n",
       "\n",
       "          s_hgnc_id s_symbol        p_id         p_label     o_entrez_id  \\\n",
       "0  NCBIGene:2847518     AFP1  RO:0002434  interacts with  NCBIGene:10911   \n",
       "1  NCBIGene:2847518     AFP1  RO:0002434  interacts with   NCBIGene:9241   \n",
       "\n",
       "    o_hgnc_id o_symbol  reference_id  reference_date  \n",
       "0  HGNC:12636     UTS2           NaN             NaN  \n",
       "1   HGNC:7866      NOG           NaN             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# msigdb\n",
    "msigdb = pd.read_csv('./msigdb/out/msigdb_edges.csv')\n",
    "print(msigdb.shape)\n",
    "msigdb.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197467, 15)\n"
     ]
    }
   ],
   "source": [
    "# concat tftargets and msigdb tg-gene edges\n",
    "edges = pd.concat([tftargets,msigdb],ignore_index=True)\n",
    "print(edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see duplicates\n",
    "len(edges[edges.duplicated(keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197267\n"
     ]
    }
   ],
   "source": [
    "# drop duplicates\n",
    "edges.drop_duplicates(inplace=True)\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build edges and nodes file\n",
    "file format: csv\n",
    "fill null wiht 'NA'. can be done with python function before saving\n",
    "##### edges\n",
    "1. `subject_id` str curie required\n",
    "2. `object_id` str curie required\n",
    "3. `property_id` str curie NA\n",
    "4. `property_label` str NA\n",
    "5. `property_description` str NA\n",
    "6. `property_uri` str NA\n",
    "7. `reference_uri` str NA\n",
    "8. `reference_supporting_text` str NA\n",
    "9. `reference_date` str NA | yyyy-mm-dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./graph'): os.makedirs('./graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select gene ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source', 'dataset', 'tf_source_id', 'gene_source_id', 'source_uri',\n",
      "       's_entrez_id', 's_hgnc_id', 's_symbol', 'p_id', 'p_label',\n",
      "       'o_entrez_id', 'o_hgnc_id', 'o_symbol', 'reference_id',\n",
      "       'reference_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# select id\n",
    "curie = 'hgnc'.lower()\n",
    "\n",
    "# give graph format \n",
    "print(edges.columns)\n",
    "edges = (   edges\n",
    "            .rename(columns={'s_hgnc_id': 'subject_id',\n",
    "                             'p_id': 'property_id',\n",
    "                             'p_label': 'property_label',\n",
    "                             'o_hgnc_id': 'object_id'\n",
    "                            })\n",
    ")\n",
    "\n",
    "curie_dct = {\n",
    "    'ro': 'http://purl.obolibrary.org/obo/',\n",
    "    'pmid': 'https://www.ncbi.nlm.nih.gov/pubmed/',\n",
    "    'encode': 'https://www.encodeproject.org/search/?searchTerm='\n",
    "}\n",
    "\n",
    "edges_l = list()\n",
    "for i, row in edges.iterrows():\n",
    "    # property uri: http://purl.obolibrary.org/obo/RO_0002434\n",
    "    property_uri = 'NA'\n",
    "    if ':' in row['property_id']:\n",
    "        property_uri = curie_dct[row['property_id'].split(':')[0].lower()]+row['property_id'].replace(':','_')       \n",
    "    \n",
    "    # reference_uri: https://www.ncbi.nlm.nih.gov/pubmed/25416956\n",
    "    # capture nan or None values, i.e. all possible nulls\n",
    "    #if (isinstance(row['reference_id'], float) and str(row['reference_id']).lower() == 'nan') or row['reference_id'] is None:\n",
    "    #    row['reference_id'] = 'NA'\n",
    "    if ':' not in str(row['reference_id']):\n",
    "        reference_uri = row['source_uri'] #row['reference_id']\n",
    "    else:\n",
    "        try:\n",
    "            reference_uri = curie_dct[row['reference_id'].split(':')[0].lower()]+row['reference_id'].split(':')[1]\n",
    "        except KeyError:\n",
    "            reference_uri = row['reference_id']\n",
    "            print('There is a reference curie with and unrecognized namespace:', row['reference_id'])\n",
    "    # build list of edges as list of dict, i.e a df, where a dict is an edge        \n",
    "    edge = dict()\n",
    "    edge['subject_id'] = row['subject_id']\n",
    "    edge['object_id'] = row['object_id']\n",
    "    edge['property_id'] = row['property_id']\n",
    "    edge['property_label'] = row['property_label']\n",
    "    edge['property_description'] = 'NA'\n",
    "    edge['property_uri'] = property_uri\n",
    "    edge['reference_uri'] = reference_uri\n",
    "    edge['reference_supporting_text'] = 'This edge comes from the {} dataset in \"{}\" source.'.format(row['dataset'].upper(),row['source']) # 'NA'\n",
    "    edge['reference_date'] = row['reference_date']\n",
    "    edges_l.append(edge)\n",
    "\n",
    "# save edges file\n",
    "pd.DataFrame(edges_l).fillna('NA').to_csv('./graph/regulation_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### nodes\n",
    "1. `id` str curie required\n",
    "2. `semantic_groups` str required\n",
    "3. `preflabel` str label required\n",
    "4. `synonyms` str NA\n",
    "5. `description` str NA\n",
    "6. **new** `name` str NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16992"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve node attributes from biothings and build dictionary\n",
    "# from biothings we retrieve: name (new attribute for short description), alias (synonyms), summary (description)\n",
    "# symbols in this case come from the original source. otherwise are gonna be retrieved from biothings as well.\n",
    "# build concept dict: {id:symbol}\n",
    "concept_dct = dict()\n",
    "for i, row in edges.iterrows():\n",
    "    # node for subject\n",
    "    concept_dct[row['subject_id']] = {\n",
    "        'preflabel': row['s_symbol'],\n",
    "        'name': None,\n",
    "        'synonyms': None,\n",
    "        'description': None\n",
    "    }\n",
    "    # node for object\n",
    "    concept_dct[row['object_id']] = {\n",
    "        'preflabel': row['o_symbol'],\n",
    "        'name': None,\n",
    "        'synonyms': None,\n",
    "        'description': None\n",
    "    }\n",
    "len(concept_dct.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trap genes without symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NCBIGene    135\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trap nan symbols, i.e. discontinued entrez gene id\n",
    "concepts_no_symbol_set = set()\n",
    "for concept in concept_dct:\n",
    "    if str(concept_dct[concept]['preflabel']) == 'nan':\n",
    "        concepts_no_symbol_set.add(concept)\n",
    "print(len(concepts_no_symbol_set))\n",
    "concepts_no_symbol_set\n",
    "concepts_l = list(concepts_no_symbol_set)\n",
    "pd.DataFrame({'id':concepts_l}).id.apply(lambda x: x.split(':')[0]).value_counts()\n",
    "# checked that all are entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-135...done.\n",
      "Finished.\n",
      "88 input query terms found no hit:\n",
      "\t['79907', '79911', '93333', '121301', '143902', '146856', '151720', '197379', '219392', '221943', '2\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>notfound</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9503</th>\n",
       "      <td>653067</td>\n",
       "      <td>1.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XAGE1B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9714</th>\n",
       "      <td>55619</td>\n",
       "      <td>1.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOCK10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id  _score notfound  symbol\n",
       "query                                 \n",
       "9503   653067    1.55      NaN  XAGE1B\n",
       "9714    55619    1.55      NaN  DOCK10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve symbol for every ncbi gene\n",
    "entrez = list()\n",
    "for concept in concept_dct:\n",
    "    if str(concept_dct[concept]['preflabel']) == 'nan':\n",
    "        entrez.append(concept.split(':')[1])\n",
    "\n",
    "mg = get_client('gene')\n",
    "df1 = mg.querymany(entrez, scopes = 'entrezgene,retired', fields='symbol', size=1, as_dataframe=True)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 4)\n",
      "47\n",
      "88\n",
      "88 entrez have no hit, i.e. withdrawn entrez from NCBI Gene\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(len(set(df1.symbol)))\n",
    "print(df1.symbol.isna().sum())\n",
    "print('88 entrez have no hit, i.e. withdrawn entrez from NCBI Gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 135\n",
      "135 47\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "# some entrez don't exist anymore >> no attributes\n",
    "# build ncbi2symbol dictionary\n",
    "e2s_df = df1.reset_index().rename(columns={'query':'entrez'}).copy()\n",
    "e2s = dict(zip(e2s_df.entrez, e2s_df.symbol))\n",
    "print(len(e2s_df.entrez),len(set(e2s_df.entrez)))\n",
    "print(len(e2s_df.symbol),len(set(e2s_df.symbol)))\n",
    "print(len(e2s))\n",
    "# dict stores nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in concept_dct:\n",
    "    if str(concept_dct[concept]['preflabel']) == 'nan' and concept.split(':')[0] == 'NCBIGene':\n",
    "        concept_dct[concept]['preflabel'] = e2s[concept.split(':')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAX1', 'PDGFRA', 'VHL', 'SLC22A6', 'SLC22A8']\n",
      "# of unique concepts with symbol: 16904\n",
      "# of unique symbols: 16870\n",
      "\n",
      "[nan, nan, nan, nan, nan]\n",
      "# of unique concepts without symbol, i.e. withdrawn: 88\n",
      "# of unique symbols: 1\n"
     ]
    }
   ],
   "source": [
    "# biothings api + dictionaries\n",
    "# input list for api: since by id we have hgnc/entrez or symbol, i am gonna use symbol\n",
    "symbols = list()\n",
    "symbols2 = list()\n",
    "for idx,symbol in concept_dct.items():\n",
    "    #id = key.split(':')[1] if ':' in key else key\n",
    "    if str(symbol['preflabel']) != 'nan':\n",
    "        symbols.append(symbol['preflabel']) \n",
    "    # withdrawn entrez\n",
    "    else:\n",
    "        symbols2.append(symbol['preflabel']) \n",
    "    \n",
    "print(symbols[0:5])    \n",
    "print('# of unique concepts with symbol:',len(symbols))\n",
    "print('# of unique symbols:',len(set(symbols)))\n",
    "print()\n",
    "print(symbols2[0:5])    \n",
    "print('# of unique concepts without symbol, i.e. withdrawn:',len(symbols2))\n",
    "print('# of unique symbols:',len(set(symbols2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-16870...done.\n",
      "Finished.\n",
      "50 input query terms found no hit:\n",
      "\t['TAL1BETAE47', 'PTF1BETA', 'NKX22', 'COREBINDINGFACTOR', 'HP1SITEFACTOR', 'TAL1ALPHAE47', 'CACCCBIN\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>alias</th>\n",
       "      <th>name</th>\n",
       "      <th>notfound</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASCL4</th>\n",
       "      <td>121549</td>\n",
       "      <td>91.830986</td>\n",
       "      <td>[HASH4, bHLHa44]</td>\n",
       "      <td>achaete-scute family bHLH transcription factor 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Basic helix-loop-helix transcription factors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOPBP1</th>\n",
       "      <td>11073</td>\n",
       "      <td>87.093254</td>\n",
       "      <td>TOP2BP1</td>\n",
       "      <td>DNA topoisomerase II binding protein 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This gene encodes a binding protein which inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           _id     _score             alias  \\\n",
       "query                                         \n",
       "ASCL4   121549  91.830986  [HASH4, bHLHa44]   \n",
       "TOPBP1   11073  87.093254           TOP2BP1   \n",
       "\n",
       "                                                    name notfound  \\\n",
       "query                                                               \n",
       "ASCL4   achaete-scute family bHLH transcription factor 4      NaN   \n",
       "TOPBP1            DNA topoisomerase II binding protein 1      NaN   \n",
       "\n",
       "                                                  summary  \n",
       "query                                                      \n",
       "ASCL4   Basic helix-loop-helix transcription factors, ...  \n",
       "TOPBP1  This gene encodes a binding protein which inte...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# api call\n",
    "symbols = list(set(symbols))\n",
    "mg = get_client('gene')\n",
    "df = mg.querymany(symbols, scopes = 'symbol,alias', fields='alias,name,summary', size=1, as_dataframe=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16870, 6)\n",
      "16992\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(len(concept_dct.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16992\n",
      "16904\n",
      "16992\n"
     ]
    }
   ],
   "source": [
    "# dictionaries {id: {name:, alias:, summary:}}\n",
    "i = 0\n",
    "print(len(concept_dct))\n",
    "for symbol, row in df.iterrows():\n",
    "    # associate concept to symbol\n",
    "    for concept in concept_dct:\n",
    "        #print(concept, symbol, concept_dct[concept]['preflabel'], row)\n",
    "        # 88 concepts without symbol (16992-88=16904 with symbol)\n",
    "        if concept_dct[concept]['preflabel'] == symbol:\n",
    "            i += 1\n",
    "            # add attributes\n",
    "            #print(concept, symbol, row['name'], row)\n",
    "            concept_dct[concept]['name'] = row['name']\n",
    "            concept_dct[concept]['synonyms'] = row['alias']\n",
    "            concept_dct[concept]['description'] = row['summary']\n",
    "print(i)\n",
    "print(len(concept_dct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16992"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a list of nodes as list of dict, i.e a df, where a dict is a node\n",
    "nodes_l = list()\n",
    "for concept in concept_dct:\n",
    "    # node for subject\n",
    "    node = dict()\n",
    "    node['id'] = concept\n",
    "    node['semantic_groups'] = 'GENE'\n",
    "    node['preflabel'] = concept_dct[concept]['preflabel']\n",
    "    node['name'] = concept_dct[concept]['name']\n",
    "    node['synonyms'] = '|'.join(list(concept_dct[concept]['synonyms'])) if isinstance(concept_dct[concept]['synonyms'], list) else concept_dct[concept]['synonyms']\n",
    "    node['description'] = concept_dct[concept]['description']\n",
    "    nodes_l.append(node)\n",
    "    \n",
    "# save nodes file    \n",
    "pd.DataFrame(nodes_l).fillna('NA').to_csv('./graph/regulation_nodes.csv', index=False)\n",
    "len(nodes_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197267"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuria/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>property_description</th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_label</th>\n",
       "      <th>property_uri</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>reference_supporting_text</th>\n",
       "      <th>reference_uri</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HGNC:8803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>http://purl.obolibrary.org/obo/RO_0002434</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>This edge comes from the TRED dataset in \"tfta...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/17202159</td>\n",
       "      <td>HGNC:8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HGNC:12687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>http://purl.obolibrary.org/obo/RO_0002434</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>This edge comes from the TRED dataset in \"tfta...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/17202159</td>\n",
       "      <td>HGNC:8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HGNC:10970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>http://purl.obolibrary.org/obo/RO_0002434</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>This edge comes from the TRED dataset in \"tfta...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/17202159</td>\n",
       "      <td>HGNC:8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HGNC:10972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>http://purl.obolibrary.org/obo/RO_0002434</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>This edge comes from the TRED dataset in \"tfta...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/17202159</td>\n",
       "      <td>HGNC:8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HGNC:25567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RO:0002434</td>\n",
       "      <td>interacts with</td>\n",
       "      <td>http://purl.obolibrary.org/obo/RO_0002434</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>This edge comes from the TRED dataset in \"tfta...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/17202159</td>\n",
       "      <td>HGNC:8615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    object_id  property_description property_id  property_label  \\\n",
       "0   HGNC:8803                   NaN  RO:0002434  interacts with   \n",
       "1  HGNC:12687                   NaN  RO:0002434  interacts with   \n",
       "2  HGNC:10970                   NaN  RO:0002434  interacts with   \n",
       "3  HGNC:10972                   NaN  RO:0002434  interacts with   \n",
       "4  HGNC:25567                   NaN  RO:0002434  interacts with   \n",
       "\n",
       "                                property_uri reference_date  \\\n",
       "0  http://purl.obolibrary.org/obo/RO_0002434     2007-01-01   \n",
       "1  http://purl.obolibrary.org/obo/RO_0002434     2007-01-01   \n",
       "2  http://purl.obolibrary.org/obo/RO_0002434     2007-01-01   \n",
       "3  http://purl.obolibrary.org/obo/RO_0002434     2007-01-01   \n",
       "4  http://purl.obolibrary.org/obo/RO_0002434     2007-01-01   \n",
       "\n",
       "                           reference_supporting_text  \\\n",
       "0  This edge comes from the TRED dataset in \"tfta...   \n",
       "1  This edge comes from the TRED dataset in \"tfta...   \n",
       "2  This edge comes from the TRED dataset in \"tfta...   \n",
       "3  This edge comes from the TRED dataset in \"tfta...   \n",
       "4  This edge comes from the TRED dataset in \"tfta...   \n",
       "\n",
       "                                  reference_uri subject_id  \n",
       "0  https://www.ncbi.nlm.nih.gov/pubmed/17202159  HGNC:8615  \n",
       "1  https://www.ncbi.nlm.nih.gov/pubmed/17202159  HGNC:8615  \n",
       "2  https://www.ncbi.nlm.nih.gov/pubmed/17202159  HGNC:8615  \n",
       "3  https://www.ncbi.nlm.nih.gov/pubmed/17202159  HGNC:8615  \n",
       "4  https://www.ncbi.nlm.nih.gov/pubmed/17202159  HGNC:8615  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./graph/regulation_edges.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>preflabel</th>\n",
       "      <th>semantic_groups</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This gene is a member of the paired box (PAX) ...</td>\n",
       "      <td>HGNC:8615</td>\n",
       "      <td>paired box 1</td>\n",
       "      <td>PAX1</td>\n",
       "      <td>GENE</td>\n",
       "      <td>HUP48|OFC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This gene encodes a cell surface tyrosine kina...</td>\n",
       "      <td>HGNC:8803</td>\n",
       "      <td>platelet derived growth factor receptor alpha</td>\n",
       "      <td>PDGFRA</td>\n",
       "      <td>GENE</td>\n",
       "      <td>CD140A|PDGFR-2|PDGFR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Von Hippel-Lindau syndrome (VHL) is a dominant...</td>\n",
       "      <td>HGNC:12687</td>\n",
       "      <td>von Hippel-Lindau tumor suppressor</td>\n",
       "      <td>VHL</td>\n",
       "      <td>GENE</td>\n",
       "      <td>HRCA1|RCA1|VHL1|pVHL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The protein encoded by this gene is involved i...</td>\n",
       "      <td>HGNC:10970</td>\n",
       "      <td>solute carrier family 22 member 6</td>\n",
       "      <td>SLC22A6</td>\n",
       "      <td>GENE</td>\n",
       "      <td>HOAT1|OAT1|PAHT|ROAT1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This gene encodes a protein involved in the so...</td>\n",
       "      <td>HGNC:10972</td>\n",
       "      <td>solute carrier family 22 member 8</td>\n",
       "      <td>SLC22A8</td>\n",
       "      <td>GENE</td>\n",
       "      <td>OAT3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description          id  \\\n",
       "0  This gene is a member of the paired box (PAX) ...   HGNC:8615   \n",
       "1  This gene encodes a cell surface tyrosine kina...   HGNC:8803   \n",
       "2  Von Hippel-Lindau syndrome (VHL) is a dominant...  HGNC:12687   \n",
       "3  The protein encoded by this gene is involved i...  HGNC:10970   \n",
       "4  This gene encodes a protein involved in the so...  HGNC:10972   \n",
       "\n",
       "                                            name preflabel semantic_groups  \\\n",
       "0                                   paired box 1      PAX1            GENE   \n",
       "1  platelet derived growth factor receptor alpha    PDGFRA            GENE   \n",
       "2             von Hippel-Lindau tumor suppressor       VHL            GENE   \n",
       "3              solute carrier family 22 member 6   SLC22A6            GENE   \n",
       "4              solute carrier family 22 member 8   SLC22A8            GENE   \n",
       "\n",
       "                synonyms  \n",
       "0             HUP48|OFC2  \n",
       "1  CD140A|PDGFR-2|PDGFR2  \n",
       "2   HRCA1|RCA1|VHL1|pVHL  \n",
       "3  HOAT1|OAT1|PAHT|ROAT1  \n",
       "4                   OAT3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./graph/regulation_nodes.csv')\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
